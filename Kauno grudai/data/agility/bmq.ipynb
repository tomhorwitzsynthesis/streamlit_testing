{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf89cbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: SBA_compos_analysis.xlsx\n",
      "  ✓ BMQ written to 'Raw Data' in SBA_compos_analysis.xlsx\n",
      "Processing: Thermo_compos_analysis.xlsx\n",
      "  ✓ BMQ written to 'Raw Data' in Thermo_compos_analysis.xlsx\n",
      "Processing: Acme_compos_analysis.xlsx\n",
      "  ✓ BMQ written to 'Raw Data' in Acme_compos_analysis.xlsx\n",
      "Processing: Kaun_compos_analysis.xlsx\n",
      "  ✓ BMQ written to 'Raw Data' in Kaun_compos_analysis.xlsx\n",
      "Processing: Ignitis_compos_analysis.xlsx\n",
      "  ✓ BMQ written to 'Raw Data' in Ignitis_compos_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ----- CONFIG -----\n",
    "FILES = [\n",
    "    \"SBA_compos_analysis.xlsx\",\n",
    "    \"Thermo_compos_analysis.xlsx\",\n",
    "    \"Acme_compos_analysis.xlsx\",\n",
    "    \"Kaun_compos_analysis.xlsx\",\n",
    "    \"Ignitis_compos_analysis.xlsx\",\n",
    "]\n",
    "SHEET = \"Raw Data\"\n",
    "\n",
    "# Column names exactly as they appear in your sheet\n",
    "COL_QUALITY = \"Quality\"\n",
    "COL_RANK = \"Rank\"\n",
    "COL_LOG_RANK = \"Log_Rank\"\n",
    "COL_N = \"query_occurrences\"\n",
    "COL_QS = \"Quality_Score\"\n",
    "COL_BMQ = \"BMQ\"\n",
    "\n",
    "def log_scale_with_clipping_lower_better(value, lo, hi):\n",
    "    v = np.clip(value, lo, hi)\n",
    "    return 1.0 - (np.log(v) - np.log(lo)) / (np.log(hi) - np.log(lo))\n",
    "\n",
    "def log_scale_with_clipping_higher_better(value, lo, hi):\n",
    "    v = np.clip(value, lo, hi)\n",
    "    return (np.log(v) - np.log(lo)) / (np.log(hi) - np.log(lo))\n",
    "\n",
    "def linear_scale_with_clipping(value, lo, hi):\n",
    "    v = np.clip(value, lo, hi)\n",
    "    return (v - lo) / (hi - lo)\n",
    "\n",
    "def compute_bmq(df):\n",
    "    \"\"\"Return a pandas Series with BMQ following your Option 2 spec.\"\"\"\n",
    "    # Basic validation\n",
    "    required = {COL_QUALITY, COL_RANK, COL_LOG_RANK, COL_N, COL_QS}\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # R_input = Log_Rank * 100, and +1 for the first data row (if any)\n",
    "    R_input = df[COL_LOG_RANK].astype(float) * 100.0\n",
    "    if len(R_input) > 0:\n",
    "        R_input.iloc[0] = R_input.iloc[0] + 1.0\n",
    "\n",
    "    # Scaled components\n",
    "    # P (Rank): lower is better, log scale, range 1..1e8\n",
    "    scaled_P = log_scale_with_clipping_lower_better(df[COL_RANK].astype(float), 1.0, 1e8)\n",
    "\n",
    "    # R (R_input): lower is better, log scale, range 1..100\n",
    "    scaled_R = log_scale_with_clipping_lower_better(R_input, 1.0, 100.0)\n",
    "\n",
    "    # n (query_occurrences): higher is better, log scale, range 1..30\n",
    "    scaled_n = log_scale_with_clipping_higher_better(df[COL_N].astype(float), 1.0, 30.0)\n",
    "\n",
    "    # Q (Quality_Score): linear, range 1..3\n",
    "    scaled_Q = linear_scale_with_clipping(df[COL_QS].astype(float), 1.0, 3.0)\n",
    "\n",
    "    score = 0.25 * (scaled_P + scaled_R + scaled_n + scaled_Q)\n",
    "\n",
    "    # Only for Quality == 'A'; others blank/NaN\n",
    "    bmq = np.where(df[COL_QUALITY].astype(str).str.upper() == \"A\", score, np.nan)\n",
    "\n",
    "    return pd.Series(bmq, index=df.index)\n",
    "\n",
    "def write_bmq_to_sheet(xlsx_path, sheet_name=SHEET):\n",
    "    # Read with pandas\n",
    "    df = pd.read_excel(xlsx_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Compute BMQ\n",
    "    bmq_series = compute_bmq(df)\n",
    "\n",
    "    # Open with openpyxl to write only the BMQ column (preserve everything else)\n",
    "    wb = load_workbook(filename=xlsx_path)\n",
    "    if sheet_name not in wb.sheetnames:\n",
    "        wb.close()\n",
    "        raise ValueError(f\"Sheet '{sheet_name}' not found in '{xlsx_path}'.\")\n",
    "\n",
    "    ws = wb[sheet_name]\n",
    "\n",
    "    # Determine header row (assume row 1)\n",
    "    headers = [cell.value for cell in ws[1]]\n",
    "\n",
    "    # Find or append BMQ column\n",
    "    try:\n",
    "        bmq_col_idx = headers.index(COL_BMQ) + 1  # 1-based\n",
    "    except ValueError:\n",
    "        bmq_col_idx = ws.max_column + 1\n",
    "        ws.cell(row=1, column=bmq_col_idx, value=COL_BMQ)\n",
    "\n",
    "    # Write values (row 2 onward)\n",
    "    for i, val in enumerate(bmq_series, start=2):\n",
    "        # Write None if NaN to keep the cell blank\n",
    "        out_val = None if (pd.isna(val)) else float(val)\n",
    "        ws.cell(row=i, column=bmq_col_idx, value=out_val)\n",
    "\n",
    "    wb.save(xlsx_path)\n",
    "    wb.close()\n",
    "\n",
    "for path in FILES:\n",
    "    print(f\"Processing: {path}\")\n",
    "    try:\n",
    "        write_bmq_to_sheet(path, SHEET)\n",
    "        print(f\"  ✓ BMQ written to '{SHEET}' in {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed on {path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c71c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ----- CONFIG -----\n",
    "FILES = [\n",
    "    \"SBA_compos_analysis.xlsx\",\n",
    "    \"Thermo_compos_analysis.xlsx\",\n",
    "    \"Acme_compos_analysis.xlsx\",\n",
    "    \"Kaun_compos_analysis.xlsx\",\n",
    "    \"Ignitis_compos_analysis.xlsx\",\n",
    "]\n",
    "SHEET = \"Raw Data\"\n",
    "OUTPUT = \"full_pr.xlsx\"\n",
    "\n",
    "def extract_company_name(filename: str) -> str:\n",
    "    # Take the part before the first underscore\n",
    "    return filename.split(\"_\", 1)[0]\n",
    "\n",
    "def merge_raw_data(files, sheet_name, output_path):\n",
    "    all_frames = []\n",
    "    for path in files:\n",
    "        try:\n",
    "            df = pd.read_excel(path, sheet_name=sheet_name)\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed reading {path}: {e}\")\n",
    "            continue\n",
    "        company = extract_company_name(path)\n",
    "        df.insert(0, \"company\", company)  # prepend column\n",
    "        all_frames.append(df)\n",
    "\n",
    "    if not all_frames:\n",
    "        raise RuntimeError(\"No data was read from any files.\")\n",
    "\n",
    "    merged = pd.concat(all_frames, ignore_index=True)\n",
    "    merged.to_excel(output_path, sheet_name=\"full\", index=False)\n",
    "    print(f\"✓ Merged {len(all_frames)} sheets into {output_path} ({len(merged)} rows).\")\n",
    "\n",
    "\n",
    "merge_raw_data(FILES, SHEET, OUTPUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
